# ==============================================================================
# AI Chief of Staff - Microservices Architecture
# ==============================================================================
#
# ENVIRONMENT VARIABLE PHILOSOPHY:
#
# This file minimizes environment variables following the principle:
# "Configuration should be database-driven, not environment-driven"
#
# WHAT'S IN ENVIRONMENT VARIABLES:
# ✓ Infrastructure URLs (DATABASE_URL, REDIS_URL, service discovery)
# ✓ Runtime settings (NODE_ENV, LOG_LEVEL)
#
# WHAT'S IN DATABASE (configured via Settings UI):
# ✓ External API keys (ANTHROPIC_API_KEY, OPENAI_API_KEY)
#   - Stored encrypted in database, retrieved by microservices
#   - Environment variable fallback for backward compatibility
# ✓ AI model selection (claude-sonnet-4-5-20250929, gpt-4o, etc.)
# ✓ AI provider selection (anthropic, openai, ollama)
# ✓ Storage configuration (storageType: local/s3, S3 bucket, credentials)
# ✓ Calendar credentials (Google OAuth tokens, Microsoft OAuth, CalDAV)
# ✓ Jira/Planner integration settings
# ✓ User preferences and dashboard settings
# ✓ Push notification keys (auto-generated VAPID)
# ✓ Redirect URIs (with localhost:3001 fallback)
# ✓ Calendar IDs (with 'primary' fallback)
#
# BENEFITS:
# - Change AI models without container restart (just update DB)
# - Change storage config without container restart (just update DB)
# - Settings UI is more user-friendly than editing .env files
# - Microservices read provider/model choice from database at runtime
#
# ==============================================================================

services:
  # ============================================================================
  # FRONTEND - React Application
  # ============================================================================
  aicos-frontend:
    container_name: aicos-frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      # Frontend uses relative /api path which nginx proxies to backend
      - VITE_API_URL=/api
    depends_on:
      - aicos-backend
    networks:
      - aicos-network
    volumes:
      - ./frontend/src:/app/src
    restart: unless-stopped

  # ============================================================================
  # BACKEND - Node.js/Express API Gateway
  # ============================================================================
  aicos-backend:
    container_name: aicos-backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      # ============================================
      # INFRASTRUCTURE (Required - cannot be in DB)
      # ============================================
      
      # Database connection string
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos
      - DB_TYPE=postgres
      
      # Cache/queue connection
      - REDIS_URL=redis://aicos-redis:6379
      
      # Microservice discovery URLs (auto-configured via Docker network)
      - AI_INTELLIGENCE_URL=http://aicos-ai-intelligence:8001
      - PATTERN_RECOGNITION_URL=http://aicos-pattern-recognition:8002
      - NL_PARSER_URL=http://aicos-nl-parser:8003
      - VOICE_PROCESSOR_URL=http://aicos-voice-processor:8004
      - CONTEXT_SERVICE_URL=http://aicos-context-service:8005
      
      # ============================================
      # RUNTIME CONFIGURATION
      # ============================================
      
      # Runtime environment (development/production)
      - NODE_ENV=development
      
      # Log verbosity (debug/info/warn/error)
      - LOG_LEVEL=info
      
      # ============================================
      # ALL OTHER CONFIG IN DATABASE (via Settings UI)
      # ============================================
      # - AI model selection (Claude Sonnet 4.5, GPT-4, etc.)
      # - Calendar credentials (Google OAuth, Microsoft OAuth, CalDAV)
      # - Jira/Planner integration settings
      # - User preferences and dashboard settings
      # - Push notification keys (auto-generated)
      # - Redirect URIs (fallback to localhost:3001 if not in DB)
      # - Calendar IDs (fallback to 'primary' if not in DB)
    depends_on:
      - aicos-postgres
      - aicos-redis
    networks:
      - aicos-network
    volumes:
      - ./backend:/app
      - /app/node_modules
      - backend-data:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # MICROSERVICES
  # ============================================================================

  # AI Intelligence Service - Task analysis with Claude
  aicos-ai-intelligence:
    container_name: aicos-ai-intelligence
    build:
      context: ./services
      dockerfile: ai-intelligence/Dockerfile
    ports:
      - "8001:8001"
    environment:
      # Infrastructure
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos
      - REDIS_URL=redis://aicos-redis:6379
      
      # Runtime
      - LOG_LEVEL=info
      
      # All configuration from database via Settings UI:
      # - API keys (anthropicApiKey, openaiApiKey)
      # - AI provider selection (anthropic, openai, ollama, bedrock)
      # - AI model selection (claude-sonnet-4-5-20250929, gpt-4o, mistral:latest, etc.)
      # - Ollama base URL, AWS Bedrock credentials
    depends_on:
      - aicos-redis
    networks:
      - aicos-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Pattern Recognition Service - ML-based insights
  aicos-pattern-recognition:
    container_name: aicos-pattern-recognition
    build:
      context: ./services
      dockerfile: pattern-recognition/Dockerfile
    ports:
      - "8002:8002"
    environment:
      # Infrastructure
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos
      - REDIS_URL=redis://aicos-redis:6379
      
      # Runtime
      - LOG_LEVEL=info
      
      # All configuration from database via Settings UI:
      # - API keys (anthropicApiKey, openaiApiKey)
      # - AI provider selection (anthropic, openai, ollama, bedrock)
      # - AI model selection (claude-sonnet-4-5-20250929, gpt-4o, mistral:latest, etc.)
      # - Ollama base URL, AWS Bedrock credentials
    depends_on:
      - aicos-postgres
      - aicos-redis
    networks:
      - aicos-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    volumes:
      # Persist ML models
      - pattern-models:/app/models
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Natural Language Parser - Task extraction
  aicos-nl-parser:
    container_name: aicos-nl-parser
    build:
      context: ./services
      dockerfile: nl-parser/Dockerfile
    ports:
      - "8003:8003"
    environment:
      # Infrastructure
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos
      - REDIS_URL=redis://aicos-redis:6379
      
      # Runtime
      - LOG_LEVEL=info
      
      # All configuration from database via Settings UI:
      # - API keys (anthropicApiKey, openaiApiKey)
      # - AI provider selection (anthropic, openai, ollama, bedrock)
      # - AI model selection (claude-sonnet-4-5-20250929, gpt-4o, mistral:latest, etc.)
      # - Ollama base URL, AWS Bedrock credentials
    depends_on:
      - aicos-redis
    networks:
      - aicos-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Voice Processor - Whisper transcription
  aicos-voice-processor:
    container_name: aicos-voice-processor
    build:
      context: ./services
      dockerfile: voice-processor/Dockerfile
    ports:
      - "8004:8004"
    environment:
      # Infrastructure
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos
      - REDIS_URL=redis://aicos-redis:6379
      
      # Runtime
      - LOG_LEVEL=info
      
      # All configuration from database via Settings UI:
      # - API keys (openaiApiKey)
      # - AI provider selection (openai, ollama)
      # - AI model selection (whisper-1, whisper:medium, etc.)
      # - Storage configuration (storageType, s3Bucket, s3 credentials, etc.)
      # - Ollama base URL
    depends_on:
      - aicos-redis
    networks:
      - aicos-network
    volumes:
      - voice-recordings:/app/data/voice-recordings
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    # Uncomment for GPU support (requires nvidia-docker)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Context Service - High-performance context retrieval (Go)
  aicos-context-service:
    container_name: aicos-context-service
    build:
      context: ./services/context-service
      dockerfile: Dockerfile
    ports:
      - "8005:8005"
    environment:
      # Database connection (Go service parses this directly)
      - DATABASE_URL=postgresql://postgres:postgres@aicos-postgres:5432/aicos?sslmode=disable
      
      # Redis for caching
      - REDIS_URL=redis://aicos-redis:6379
      
      # Log verbosity
      - LOG_LEVEL=info
    depends_on:
      - aicos-postgres
      - aicos-redis
    networks:
      - aicos-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ============================================================================
  # OPTIONAL SERVICES (Uncomment to enable)
  # ============================================================================

  # Ollama - Local AI Models (Optional)
  # Uncomment to run AI models locally for privacy/offline use
  # aicos-ollama:
  #   container_name: aicos-ollama
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   networks:
  #     - aicos-network
  #   restart: unless-stopped
  #   # Uncomment for GPU support
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

  # Radicale - CalDAV/CardDAV Server (Optional)
  # Uncomment for built-in calendar storage (alternative to Google/Microsoft)
  # aicos-radicale:
  #   container_name: aicos-radicale
  #   image: tomsquest/docker-radicale:latest
  #   ports:
  #     - "5232:5232"
  #   environment:
  #     - RADICALE_AUTH_TYPE=htpasswd
  #   volumes:
  #     - radicale-data:/data
  #     - radicale-config:/config
  #   networks:
  #     - aicos-network
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:5232/"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

  # ============================================================================
  # DATA LAYER
  # ============================================================================

  # PostgreSQL Database
  aicos-postgres:
    container_name: aicos-postgres
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=aicos
      - POSTGRES_INITDB_ARGS=--encoding=UTF8 --locale=en_US.UTF-8
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/migrations:/docker-entrypoint-initdb.d
    networks:
      - aicos-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache & Queue
  aicos-redis:
    container_name: aicos-redis
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - aicos-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # MONITORING (Optional - uncomment for production)
  # ============================================================================

  # # Prometheus - Metrics collection
  # prometheus:
  #   image: prom/prometheus:latest
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus-data:/prometheus
  #   networks:
  #     - aicos-network
  #   restart: unless-stopped

  # # Grafana - Metrics visualization
  # grafana:
  #   image: grafana/grafana:latest
  #   ports:
  #     - "3030:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #   volumes:
  #     - grafana-data:/var/lib/grafana
  #   networks:
  #     - aicos-network
  #   restart: unless-stopped

networks:
  aicos-network:
    driver: bridge
    name: aicos-network

volumes:
  backend-data:
    driver: local
  postgres-data:
    driver: local
  redis-data:
    driver: local
  pattern-models:
    driver: local
  voice-recordings:
    driver: local
  # ollama-data:
  #   driver: local
  # radicale-data:
  #   driver: local
  # radicale-config:
  #   driver: local
  # prometheus-data:
  #   driver: local
  # grafana-data:
  #   driver: local
